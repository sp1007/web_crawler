# Progress Bar Feature - Complete Guide

## ğŸ“Š Overview

Package hiá»‡n cÃ³ **thanh tiáº¿n Ä‘á»™ (progress bar)** Ä‘á»ƒ theo dÃµi quÃ¡ trÃ¬nh crawl real-time!

## âœ¨ TÃ­nh nÄƒng

- âœ… Real-time progress tracking
- âœ… Visual progress bar vá»›i tqdm
- âœ… Hiá»ƒn thá»‹: Percentage, Current/Total, Time, ETA, Speed
- âœ… Há»— trá»£ cáº£ WebCrawler vÃ  ChainCrawler
- âœ… Per-step progress trong chain crawling
- âœ… CÃ³ thá»ƒ táº¯t/báº­t dá»… dÃ ng

## ğŸš€ Quick Start

### Basic Usage

```python
from web_crawler import WebCrawler

urls = ["https://example.com"] * 50

# WITH progress bar (máº·c Ä‘á»‹nh)
crawler = WebCrawler(
    urls=urls,
    show_progress=True  # Default = True
)

crawler.crawl()

# Output:
# Crawling URLs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:15<00:00, 3.33url/s]
```

### Disable Progress Bar

```python
# WITHOUT progress bar
crawler = WebCrawler(
    urls=urls,
    show_progress=False
)

crawler.crawl()
# Chá»‰ cÃ³ logs, khÃ´ng cÃ³ progress bar
```

## ğŸ”— Chain Crawler Progress

Má»—i step trong chain cÃ³ progress bar riÃªng:

```python
from web_crawler import ChainCrawler, ChainStep

steps = [
    ChainStep("Step 1", parser1, extract_urls),
    ChainStep("Step 2", parser2, None)
]

crawler = ChainCrawler(
    initial_urls=urls,
    steps=steps,
    show_progress=True  # Progress cho má»—i step
)

crawler.crawl()

# Output:
# Step 1: Extract Links: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00, 2.00url/s]
# Step 2: Parse Content:  100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:15<00:00, 3.33url/s]
```

## ğŸ“Š Progress Information

Progress bar hiá»ƒn thá»‹ cÃ¡c thÃ´ng tin:

```
Crawling URLs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:15<00:00, 3.33url/s]
               â”‚    â”‚            â”‚  â”‚    â”‚        â”‚        â”‚
               â”‚    â”‚            â”‚  â”‚    â”‚        â”‚        â””â”€ Speed (URLs/sec)
               â”‚    â”‚            â”‚  â”‚    â”‚        â””â”€ ETA (estimated time)
               â”‚    â”‚            â”‚  â”‚    â””â”€ Time elapsed
               â”‚    â”‚            â”‚  â””â”€ Current/Total
               â”‚    â”‚            â””â”€ Current number
               â”‚    â””â”€ Visual progress bar
               â””â”€ Percentage (0-100%)
```

## ğŸ¯ When to Use

### Use Progress Bar (show_progress=True)

âœ… **Good for:**
- Crawling nhiá»u URLs (>10)
- Interactive/terminal sessions
- Development vÃ  debugging
- Muá»‘n biáº¿t thá»i gian cÃ²n láº¡i
- Monitor performance

### Disable Progress Bar (show_progress=False)

âœ… **Good for:**
- Production logging
- Crawling Ã­t URLs (<5)
- Cron jobs / background tasks
- File output cáº§n clean
- CI/CD pipelines

## ğŸ’¡ Examples

### Example 1: Development Mode

```python
# Development: Enable progress
crawler = WebCrawler(
    urls=development_urls,
    show_progress=True,
    max_workers=5
)
```

### Example 2: Production Mode

```python
# Production: Disable progress, use clean logs
crawler = WebCrawler(
    urls=production_urls,
    show_progress=False,
    max_workers=20
)
```

### Example 3: Large Crawl

```python
# Large crawl - Progress bar ráº¥t há»¯u Ã­ch!
urls = get_urls()  # 1000+ URLs

crawler = WebCrawler(
    urls=urls,
    show_progress=True,  # Track progress!
    max_workers=15
)

stats = crawler.crawl()
# Báº¡n sáº½ tháº¥y progress update real-time
```

### Example 4: Chain Crawl

```python
# Chain with progress per step
crawler = ChainCrawler(
    initial_urls=["https://shop.com/category"],
    steps=[
        ChainStep("Categories", cat_parser, get_products),
        ChainStep("Products", prod_parser, get_details),
        ChainStep("Details", detail_parser, None)
    ],
    show_progress=True  # Progress cho cáº£ 3 steps
)

crawler.crawl()
# Má»—i step sáº½ cÃ³ progress bar riÃªng!
```

## ğŸ”§ Technical Details

### Implementation

- Sá»­ dá»¥ng **tqdm** library
- Async-compatible vá»›i `tqdm.asyncio`
- Zero performance overhead khi disabled
- Thread-safe

### Performance Impact

- **With progress**: ~1-2% overhead (negligible)
- **Without progress**: No overhead
- KhÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n crawl speed

## ğŸ› Troubleshooting

### Progress bar khÃ´ng hiá»‡n?

```python
# Äáº£m báº£o show_progress=True
crawler = WebCrawler(urls=urls, show_progress=True)
```

### Progress bar bá»‹ nháº£y?

- Normal behavior vá»›i async tasks
- Progress cÃ³ thá»ƒ khÃ´ng tuyáº¿n tÃ­nh vÃ¬ concurrent

### Muá»‘n custom progress format?

```python
# Hiá»‡n táº¡i chÆ°a support custom format
# Sáº½ thÃªm trong version tÆ°Æ¡ng lai
```

## ğŸ“ Best Practices

1. **Enable trong development**
   ```python
   if ENV == 'development':
       show_progress = True
   else:
       show_progress = False
   ```

2. **Disable trong production logs**
   ```python
   crawler = WebCrawler(
       urls=urls,
       show_progress=False  # Clean logs
   )
   ```

3. **Use vá»›i large datasets**
   ```python
   if len(urls) > 50:
       show_progress = True  # Helpful for large crawls
   ```

## ğŸ“š Complete Example

File: `example_progress_bar.py`

```python
from web_crawler import WebCrawler

# Example vá»›i nhiá»u URLs
urls = ["https://example.com"] * 100

print("Starting crawl with progress bar...")

crawler = WebCrawler(
    urls=urls,
    max_workers=10,
    show_progress=True  # Enable progress
)

stats = crawler.crawl()

print(f"\nCompleted!")
print(f"Success: {stats['success']}/{stats['total']}")
print(f"Duration: {stats['duration']}s")
print(f"Speed: {stats['total']/stats['duration']:.1f} URLs/sec")
```

## ğŸ“ Summary

**Progress Bar giÃºp báº¡n:**
- âœ… Theo dÃµi tiáº¿n Ä‘á»™ crawl
- âœ… Biáº¿t thá»i gian cÃ²n láº¡i
- âœ… Monitor performance
- âœ… Giáº£m lo láº¯ng khi crawl lÃ¢u
- âœ… Debug issues dá»… hÆ¡n

**Default behavior:**
- `show_progress=True` - Progress bar enabled
- CÃ³ thá»ƒ táº¯t vá»›i `show_progress=False`

---

**Version:** 1.1.0  
**Feature Added:** 2024-02-02  
**Dependencies:** tqdm>=4.66.0
